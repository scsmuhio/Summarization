{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICASSP Joint_loss CODE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9wMXc7UV59W"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Vfr-nuWA7y"
      },
      "source": [
        "!pip install indic\n",
        "!pip install indic-nlp-library\n",
        "!pip install transformers\n",
        "!pip install wxconv\n",
        "!pip install polyglot_tokenizer\n",
        "\n",
        "!pip install torch_sparse\n",
        "!pip install torch_geometric\n",
        "!pip install torch_scatter\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slN2FHIfWDVV"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.util import ngrams\n",
        "\n",
        "import sys\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from itertools import combinations\n",
        "from collections import Counter\n",
        "from indicnlp.tokenize import sentence_tokenize\n",
        "from indicnlp.tokenize import indic_tokenize \n",
        "from nltk.tokenize import word_tokenize\n",
        "import polyglot_tokenizer\n",
        "from polyglot_tokenizer import Tokenizer\n",
        " \n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "import xlrd\n",
        "import csv\n",
        "from wxconv import WXC\n",
        "\n",
        "import gensim\n",
        "import sklearn\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfTransformer \n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "\n",
        "import scipy\n",
        "from scipy import spatial\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# The path to the local git repo for Indic NLP library\n",
        "INDIC_NLP_LIB_HOME=r\"C:\\Users\\ankunchu\\Documents\\src\\indic_nlp_library\"\n",
        "# The path to the local git repo for Indic NLP Resources\n",
        "INDIC_NLP_RESOURCES=r\"C:\\Users\\ankunchu\\Documents\\src\\indic_nlp_resources\"\n",
        "sys.path.append(r'{}\\src'.format(INDIC_NLP_LIB_HOME))# The path to the local git repo for Indic NLP library"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4pl_1DFhBKe"
      },
      "source": [
        "import torch \n",
        "from torch.autograd import Variable\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "import transformers\n",
        "from transformers import BertConfig, BertModel\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH5ZHC1Kv4-8"
      },
      "source": [
        "#BERT model\n",
        "# Download model and configuration from S3 and cache.\n",
        "\n",
        "bert_model = BertModel.from_pretrained('subbareddyiiit/BERT-NLP')\n",
        "config = BertConfig.from_pretrained(\"subbareddyiiit/BERT-NLP\",output_attentions=True)  \n",
        "bert_tk = AutoTokenizer.from_pretrained(\"subbareddyiiit/BERT-NLP\")  \n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU4gEGm9kpbf"
      },
      "source": [
        "def get_wx_sentence(sent):\n",
        "  con = WXC(order='utf2wx',lang='tel')  \n",
        "  wx_sentence = con.convert(sent)  \n",
        "  return wx_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUKb5nBmx8aH"
      },
      "source": [
        "#returns a 768(for bert) size embedding \n",
        "\n",
        "def bert_sentence_embedding(sentence, model):\n",
        "  wx_sent = get_wx_sentence(sentence)\n",
        "  tokens = bert_tk.tokenize(wx_sent)\n",
        "  count = 0\n",
        "  for each_word in tokens:\n",
        "    if (each_word=='.' or each_word=='-' or each_word=='\\\\' or each_word=='_' or each_word==',' or each_word==\"'\" or each_word=='[' or each_word==']' or each_word=='(' or each_word==')' or each_word=='*' or each_word==';' or each_word=='|'  or each_word==':'  or each_word=='-'or each_word=='?'or each_word=='!' or each_word==\"\\/\"):\n",
        "      count += 1\n",
        "  if (count >= (len(tokens)/2)):\n",
        "    return []\n",
        "    \n",
        "  sent = bert_tk.encode(sentence)\n",
        "  sent = torch.tensor(sent).unsqueeze(0)\n",
        "  output = model(sent)\n",
        "  final_output = output.pooler_output.detach().numpy()\n",
        "  return final_output[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXuF_nTbWRJl"
      },
      "source": [
        "class Document:\n",
        "  def __init__(self, doc_num):\n",
        "    self.doc_num = doc_num\n",
        "      \n",
        "  def add_clustermap(self, labels, k):\n",
        "    temp = {}\n",
        "    for i in range(k):\n",
        "      temp[i] = []\n",
        "    for i,each_label in enumerate(labels):\n",
        "      temp[each_label].append(i)\n",
        "    self.cluster_map = temp\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDooO4KCx78j"
      },
      "source": [
        "#pre-processing step \n",
        "\n",
        "def pre_process_sentences(sentences):\n",
        "  sentences = sentences.replace('\\u200c','')\n",
        "  sentences = sentences.replace('\\\\u200c','')\n",
        "  sentences = sentences.replace('\\\\u200d','')\n",
        "  sentences = sentences.split('[')[1]\n",
        "  sentences = sentences.split(']')[0]\n",
        "  sentences = re.split(\"', '|', \\\"|\\\", '|\\\", \\\"\",  sentences)\n",
        "  n = len(sentences)\n",
        "  if (sentences[0][0] == \"'\"):\n",
        "    sentences[0] = sentences[0].split(\"'\")[1]\n",
        "  elif (sentences[0][0] == '\"'):\n",
        "    sentences[0] = sentences[0].split('\"')[1]\n",
        "  else:\n",
        "    print(\"character = \", sentences[0][0])\n",
        "  \n",
        "  m = len(sentences[n-1])\n",
        "  if (sentences[n-1][m-1] == \"'\"):\n",
        "    sentences[n-1] = sentences[n-1].split(\"'\")[0]    \n",
        "  elif (sentences[n-1][m-1] == '\"'):\n",
        "    sentences[n-1] = sentences[n-1].split('\"')[0] \n",
        "  else:\n",
        "    print(\"ending character = \", sentences[n-1][m-1])\n",
        "  return sentences\n",
        "\n",
        "\n",
        "def pre_process_highlights(sentences):\n",
        "  sentences = sentences.replace('\\u200c','')\n",
        "  sentences = sentences.replace('\\\\u200c','')\n",
        "  sentences = sentences.replace('\\\\u200d','')\n",
        "  sentences = sentences.split('[')[1]\n",
        "  sentences = sentences.split(']')[0]\n",
        "  sentences = sentences.split(\"', '\")\n",
        "  sentences[0] = sentences[0].split(\"'\")[1]\n",
        "  n = len(sentences)\n",
        "  sentences[n-1] = sentences[n-1].split(\"'\")[0]\n",
        "  return sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_da00lMndOW"
      },
      "source": [
        "def get_clusters( embeds, k):\n",
        "  clustering = SpectralClustering(n_clusters=k, assign_labels=\"discretize\", random_state=0).fit(embeds)\n",
        "  return clustering.labels_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4e5b5AfnBSz"
      },
      "source": [
        "#dataset you want to try upon\n",
        "final_data = open('/content/drive/My Drive/summarization/samyam_data/data/final_final_samyamdata.csv')\n",
        "\n",
        "count = 0\n",
        "data_reader = csv.reader(final_data)\n",
        "k = 3   #no.of clusters\n",
        "emb_dim = 768     \n",
        "\n",
        "all_documents = []\n",
        "count=0\n",
        "\n",
        "for row in data_reader:\n",
        "  # try:\n",
        "    if count ==0:\n",
        "      count=1\n",
        "      continue\n",
        "    doc = Document(row[1])\n",
        "    highlights = pre_process_highlights(row[4])\n",
        "    sentences = pre_process_sentences(row[7])\n",
        "    setattr(doc, \"highlights\", highlights)\n",
        "    setattr(doc, \"raw_sentences\", sentences)\n",
        "    \n",
        "    embeds = []\n",
        "    for sent in sentences:\n",
        "      temp = bert_sentence_embedding(sent, bert_model)\n",
        "      embeds.append(temp)\n",
        "    setattr(doc, \"sent_embeds\", embeds)\n",
        "    if (len(embeds)!=len(sentences)):\n",
        "      print(\"sentence improper = \", sentences)\n",
        "      raise ValueError\n",
        "    all_documents.append(doc)  \n",
        "    count += 1\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0YZIdhBomAC"
      },
      "source": [
        "#Getting document representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44C64HYpQnlj"
      },
      "source": [
        "# getting document embeddings by summation of sentence representations\n",
        "\n",
        "def get_document_embedding(all_documents):       \n",
        "  doc_embeds = []\n",
        "  for each_doc in all_documents:\n",
        "    doc_embedding = np.zeros(emb_dim)\n",
        "    for sent in each_doc.sent_embeds:\n",
        "      doc_embedding = np.add(doc_embedding, sent)\n",
        "    doc_embedding = doc_embedding/len(each_doc.sent_embeds)\n",
        "    doc_embeds.append(doc_embedding)\n",
        "  return doc_embeds\n",
        "\n",
        "doc_embeds1 = get_document_embedding(all_documents)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBkBN9cqqLWE"
      },
      "source": [
        "#Padding sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TntsKF4oQRC"
      },
      "source": [
        "def get_max_length(all_documents):\n",
        "  max_l = 0\n",
        "  for each_doc in all_documents:\n",
        "    if max_l < len(each_doc.sent_embeds):\n",
        "      max_l = len(each_doc.sent_embeds)\n",
        "  print(max_l)\n",
        "  return max_l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUyzRC6NovZt"
      },
      "source": [
        "def pad_sentences(max_length):\n",
        "  for i in range(len(all_documents)):\n",
        "    req = max_length -len(all_documents[i].sent_embeds)\n",
        "    if req >0:\n",
        "      added = np.zeros((req, emb_dim))\n",
        "      all_documents[i].sent_embeds.extend(added)\n",
        "      add_labels = [-1 for i in range(req)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMHXbdrXqXda"
      },
      "source": [
        "max_num_of_sent = get_max_length(all_documents)\n",
        "pad_sentences(max_num_of_sent)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VKthy22tUiZ"
      },
      "source": [
        "# Document Graph Construction \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlI5Bo42tTSm"
      },
      "source": [
        "import sklearn\n",
        "import scipy\n",
        "from scipy import spatial\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import sparse\n",
        "\n",
        "def get_cosine_similarity(sent_a, sent_b):\n",
        "  return (1 - spatial.distance.cosine(sent_a, sent_b))\n",
        "\n",
        "def doc_edge_index(x, threshold):\n",
        "  n = len(x)\n",
        "  pos_edge_index_r = []\n",
        "  pos_edge_index_c = []\n",
        "  neg_edge_index_r = []\n",
        "  neg_edge_index_c = []\n",
        "  for i in range(n):\n",
        "    for j in range(i+1,n):\n",
        "      try:\n",
        "        sent1 = x[i]\n",
        "        sent2 = x[j]\n",
        "        score = get_cosine_similarity( sent1, sent2)\n",
        "      except:\n",
        "        print(\"error = \", sent1, sent2)\n",
        "        raise ValueError\n",
        "      if (score > threshold):\n",
        "        pos_edge_index_r.append(i)\n",
        "        pos_edge_index_c.append(j)\n",
        "        pos_edge_index_r.append(j)\n",
        "        pos_edge_index_c.append(i)\n",
        "      else:\n",
        "        neg_edge_index_r.append(i)\n",
        "        neg_edge_index_c.append(j)\n",
        "        neg_edge_index_r.append(j)\n",
        "        neg_edge_index_c.append(i)\n",
        "  pos_edge_index = torch.tensor([pos_edge_index_r, pos_edge_index_c])\n",
        "  neg_edge_index = torch.tensor([neg_edge_index_r, neg_edge_index_c])\n",
        "  return pos_edge_index, neg_edge_index\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gKtDC9vtcTc"
      },
      "source": [
        "#edge index for document noded graph\n",
        "\n",
        "doc_threshold = 0.997\n",
        "doc_embeds_pos_edge_index, doc_embeds_neg_edge_index = doc_edge_index(doc_embeds1, doc_threshold)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGZpKcX8qAWx"
      },
      "source": [
        "# **Document Encoding**\n",
        " > Document graph constructed is passed through GAE_doc to obtain document representations.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_-KPEaTe4eT"
      },
      "source": [
        "from torch_geometric.nn import GAE\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "215WbW22p_Aw"
      },
      "source": [
        "\n",
        "class Document_Encoder_GAE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Document_Encoder_GAE, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
        "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOMrlCH1p9MQ"
      },
      "source": [
        "import shutil\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    f_path = checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA52_KR5qsfD"
      },
      "source": [
        "doc_gae_model = GAE(Document_Encoder_GAE(768, 256))\n",
        "doc_optimizer = torch.optim.RMSprop(doc_gae_model.parameters() , lr=1e-4, weight_decay=5e-4)\n",
        "print(\"optimizer = \", doc_optimizer)\n",
        "\n",
        "#number of epochs\n",
        "train_loss_min = np.Inf\n",
        "for t in range(40):\n",
        "    print(\" starting epoch = \", t)\n",
        "    doc_gae_model.train()\n",
        "    doc_optimizer.zero_grad()\n",
        "    doc_em = torch.FloatTensor(doc_embeds1)\n",
        "    output = doc_gae_model.encode(doc_em, doc_embeds_pos_edge_index)\n",
        "    train_loss = doc_gae_model.recon_loss(output, doc_embeds_pos_edge_index)\n",
        "    train_loss.backward()\n",
        "    doc_optimizer.step()\n",
        "    doc_gae_model.eval()\n",
        "\n",
        "    checkpoint = {\n",
        "            'epoch': t + 1,\n",
        "            'valid_loss_min': train_loss,\n",
        "            'state_dict1': doc_gae_model.state_dict(),\n",
        "            'optimizer': doc_optimizer.state_dict(),}\n",
        "\n",
        "    save_ckp(checkpoint, False, 'doc_joint_checkpoint1.pt', 'doc_joint_best_model1.pt')\n",
        "    print(\"loss = \", train_loss)\n",
        "    if train_loss <= train_loss_min:\n",
        "      print(' loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(train_loss_min,train_loss))\n",
        "      save_ckp(checkpoint, True,  'doc_joint_checkpoint2.pt',  'doc_joint_best_model2.pt')\n",
        "      train_loss_min = train_loss\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9itNxSj1ACH"
      },
      "source": [
        "final_doc_embeds = doc_gae_model.encode(torch.FloatTensor(doc_embeds1), doc_embeds_pos_edge_index )\n",
        "print(final_doc_embeds.shape)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvmBoVTHqEZo"
      },
      "source": [
        "# **Sentence Encoding and Summary Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5XyTslFqYCE"
      },
      "source": [
        "# Sentence Graph construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1Ba18fmqDJQ"
      },
      "source": [
        "def sent_edge_index(x, threshold):\n",
        "  n = len(x.raw_sentences)\n",
        "  pos_edge_index_r = []\n",
        "  pos_edge_index_c = []\n",
        "  neg_edge_index_r = []\n",
        "  neg_edge_index_c = []\n",
        "  for i in range(n):\n",
        "    for j in range(i+1,n):\n",
        "      try:\n",
        "        sent1 = x.sent_embeds[i]\n",
        "        sent2 = x.sent_embeds[j]\n",
        "        score = get_cosine_similarity( sent1, sent2)\n",
        "      except:\n",
        "        print(\"error = \", x.sent_embeds.shape)\n",
        "        raise ValueError\n",
        "      if (score > threshold):\n",
        "        pos_edge_index_r.append(i)\n",
        "        pos_edge_index_c.append(j)\n",
        "        pos_edge_index_r.append(j)\n",
        "        pos_edge_index_c.append(i)\n",
        "      else:\n",
        "        neg_edge_index_r.append(i)\n",
        "        neg_edge_index_c.append(j)\n",
        "        neg_edge_index_r.append(j)\n",
        "        neg_edge_index_c.append(i)\n",
        "  pos_edge_index = torch.tensor([pos_edge_index_r, pos_edge_index_c])\n",
        "  neg_edge_index = torch.tensor([neg_edge_index_r, neg_edge_index_c])\n",
        "  return pos_edge_index, neg_edge_index\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq4YmusUqCsP"
      },
      "source": [
        "sent_threshold = 0.99\n",
        "\n",
        "for i,each_doc in enumerate(all_documents):\n",
        "  pos_edge_index, neg_edge_index =sent_edge_index(each_doc, sent_threshold)\n",
        "  setattr(each_doc, \"pos_edge_index\", pos_edge_index)\n",
        "  setattr(each_doc, \"neg_edge_index\", neg_edge_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEzGZBf8hdEU"
      },
      "source": [
        "#Sentence Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwBLHFG7gkRC"
      },
      "source": [
        "class Encoder_GAE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Encoder_GAE, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
        "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeVPVFasNYoq"
      },
      "source": [
        "#Clustering and Cluster Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2jbs1priv53"
      },
      "source": [
        "class RNN_model(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layer_dim):\n",
        "    super(RNN_model, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.layer_dim = layer_dim\n",
        "    self.input_dim = input_dim\n",
        "    \n",
        "    self.rnn = torch.nn.GRU(self.input_dim, self.hidden_dim, self.layer_dim, batch_first=True)\n",
        "\n",
        "  \n",
        "  def forward(self, x, sent_embeds):\n",
        "    #modify the document to get the proper input\n",
        "    final_input = []\n",
        "    lengths = []\n",
        "\n",
        "    len_sent = len(x.raw_sentences)\n",
        "    copy_sent = sent_embeds[:len_sent].clone().detach()\n",
        "    labels = get_clusters(copy_sent, k)\n",
        "    x.add_clustermap(labels, k)\n",
        "    req = max_num_of_sent -len(x.raw_sentences)\n",
        "    if req >0:\n",
        "      add_labels = [-1 for i in range(req)]\n",
        "      labels = np.append(labels, add_labels)\n",
        "    setattr(x, \"labels\", labels)\n",
        "\n",
        "    map = x.cluster_map\n",
        "\n",
        "    for key,value in map.items():\n",
        "      temp = torch.empty((len(value),self.input_dim,))\n",
        "      for l,each_val in enumerate(value):\n",
        "        temp[l] = sent_embeds[each_val]\n",
        "      if (len(value) == 0):\n",
        "        lengths.append(1)\n",
        "        final_input.append(torch.zeros(self.input_dim))\n",
        "      else:\n",
        "        final_input.append(temp)\n",
        "        lengths.append(len(value))\n",
        "\n",
        "    b = torch.nn.utils.rnn.pad_sequence(final_input, batch_first=True)    \n",
        "    my_packed_seq = torch.nn.utils.rnn.pack_padded_sequence(b, lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "    # Initialize hidden state with zeros  (change initialization)\n",
        "    h0 = torch.zeros(self.layer_dim, len(final_input), self.hidden_dim)\n",
        "    out, hn = self.rnn(my_packed_seq, h0)\n",
        "    unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
        "\n",
        "    #get proper document wise cluster embeddings\n",
        "    final_clu_embeds = torch.zeros((k,self.hidden_dim))\n",
        "\n",
        "    for j in range(k):\n",
        "      final_clu_embeds[j] = unpacked[j,unpacked_len[j]-1,:]\n",
        "    return final_clu_embeds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i1lZMowDPXz"
      },
      "source": [
        "#Summary generation\n",
        "The actual model in order to find the top k sentences in the document. \n",
        "\n",
        "Gets the relevance and position scores of each sentence and then finds the top k sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmIcz3iLp17p"
      },
      "source": [
        "class Summary_model(torch.nn.Module):\n",
        "  def __init__(self,Dim, H1):\n",
        "    super(Summary_model, self).__init__()\n",
        "    self.linear1 = torch.nn.utils.weight_norm(torch.nn.Linear(Dim, H1), name='weight')\n",
        "    \n",
        "\n",
        "  def get_salience_scores(self, doc_scores, labels):\n",
        "    clu_scores = torch.zeros(k+1)\n",
        "    new_scores = torch.zeros(len(doc_scores))\n",
        "    for i in range(len(doc_scores)):\n",
        "      clus_num = labels[i]\n",
        "      clu_scores[clus_num+1] = torch.add(clu_scores[clus_num+1], doc_scores[i])\n",
        "    clu_scores[0] = 0         #padded sentences\n",
        "\n",
        "    for i in range(len(doc_scores)):\n",
        "      clus_num = labels[i]\n",
        "      if (clus_num+1==0) :\n",
        "        new_scores[i] = 0.0\n",
        "      else:\n",
        "        new_scores[i] = torch.div(doc_scores[i],(clu_scores[clus_num+1]))\n",
        "    return new_scores\n",
        "  \n",
        "\n",
        "  def append_cluster_embeds(self, labels, sentences, clu_embed):\n",
        "    size_em = 128     #cluster embedding size (hidden dimension)\n",
        "    size = 256+size_em  #gcn output sentence embedding     \n",
        "    append_embeds = torch.zeros( (sentences.shape[0], size ) )\n",
        "    \n",
        "    for i,each_sent in enumerate(sentences):\n",
        "      l = labels[i]\n",
        "      if (l == -1):\n",
        "        cl_em = torch.zeros(size_em)\n",
        "        temp = torch.cat(( torch.tensor(sentences[i]), torch.zeros(size_em, requires_grad=True)  ), 0)\n",
        "      else:\n",
        "        temp = torch.cat((torch.tensor(sentences[i]), clu_embed[l]), 0)\n",
        "      append_embeds[i] = temp\n",
        "    return append_embeds\n",
        "  \n",
        "  def get_position_score(self,x):\n",
        "    pos_scores = torch.zeros(len(x.sent_embeds))\n",
        "    N = len(x.raw_sentences)\n",
        "    for i in range(N):\n",
        "      value = (i+1)/(N ** (1./3))\n",
        "      pos_scores[i] = max(0.5, math.exp(-value))\n",
        "    return pos_scores\n",
        "\n",
        "  \n",
        "  def forward(self, x, cluster_embeds, sent_embeds):\n",
        "    #access the embeddings\n",
        "    final_embeds = self.append_cluster_embeds(x.labels, sent_embeds, cluster_embeds)\n",
        "    scores = self.linear1(final_embeds)\n",
        "    scores = torch.tanh(scores)\n",
        "    sal_scores = self.get_salience_scores(scores, x.labels)\n",
        "    pos_scores = self.get_position_score(x)\n",
        "    final_scores = torch.add(0.4*sal_scores, 0.6*pos_scores)\n",
        "    return final_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4ZjSK0Jmur7"
      },
      "source": [
        "class Ensemble_model(torch.nn.Module):\n",
        "  def __init__(self, model1,model2):\n",
        "    super(Ensemble_model, self).__init__()\n",
        "    self.model1 = model1\n",
        "    self.model2 = model2\n",
        "\n",
        "  def forward(self, x, sent_embeds):\n",
        "    x1 = self.model1(x, sent_embeds)\n",
        "    x2 = self.model2(x, x1, sent_embeds) \n",
        "    return x2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTAghbK9qUhB"
      },
      "source": [
        "#Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgP6ysLviSul"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "#Contrastive Loss function\n",
        "\n",
        "class ContrastiveLoss(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, margin):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.eps = 1e-9\n",
        "\n",
        "    def forward(self, output1, output2, target, size_average=True):\n",
        "        distances = (output2 - output1).pow(2).sum(0)  # squared distances\n",
        "        losses = 0.5 * (float(target) * distances + float(1 + -1 * target) * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))\n",
        "        return losses.mean() if size_average else losses.sum()\n",
        "\n",
        "\n",
        "def logcosh(y_t, y_prime_t):\n",
        "  ey_t = y_t - y_prime_t\n",
        "  return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaCo0J1nLu7V"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def my_loss_function(y_pred, y_true, x, sent_embeds):\n",
        "\n",
        "  summary = torch.zeros(256, requires_grad=True)\n",
        "  final_scores = torch.zeros((len(y_pred),257))\n",
        " \n",
        "  for i in range(len(y_pred)):\n",
        "    final_scores[i][0] = y_pred[i]\n",
        "    final_scores[i][1:] = torch.tensor(sent_embeds[i], requires_grad=True)  \n",
        "  \n",
        "  sorted, indices = torch.sort(final_scores, 0, descending=True)\n",
        "  val = 0\n",
        "  for i in range(top_k_sent):\n",
        "    val = val + sorted[i,0]\n",
        "\n",
        "  for i in range(top_k_sent):\n",
        "    summary = torch.add(summary, torch.mul(sorted[i, 1:], sorted[i,0]) ) \n",
        "  num = top_k_sent*val\n",
        "  summary = torch.div(summary,num)\n",
        "  con_loss = ContrastiveLoss(0.5)\n",
        "  loss1 = con_loss(y_true,summary, 1.0 )\n",
        "  return loss1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ovN1pdzBCQ4"
      },
      "source": [
        "#Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jFyt1JRX1lY"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(all_documents, final_doc_embeds.detach(), test_size=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8G5oCU8EQZm"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlvUwW6ZLwi9"
      },
      "source": [
        "import math\n",
        "\n",
        "Dim = 768  \n",
        "top_k_sent = 3\n",
        "input_dim = Dim   \n",
        "hidden_dim = 128 #cluster dimension  \n",
        "layer_dim = 2\n",
        "gcn_out_dim = 256 #encoder bottle neck expected dimension \n",
        "\n",
        "#with gae\n",
        "gaemodel = GAE(Encoder_GAE(Dim, gcn_out_dim))\n",
        "model1 = RNN_model(gcn_out_dim, hidden_dim, layer_dim)\n",
        "model2 = Summary_model(gcn_out_dim+hidden_dim, 1)\n",
        "final_model = Ensemble_model( model1, model2)\n",
        "all_params = list(final_model.parameters()) + list(gaemodel.parameters())\n",
        "optimizer = torch.optim.RMSprop(all_params, lr=5e-4, weight_decay=5e-4)\n",
        "\n",
        "print(\"optimizer = \", optimizer)\n",
        "\n",
        "#number of epochs\n",
        "\n",
        "train_loss_min = np.Inf\n",
        "for t in range(40):\n",
        "    print(\" starting epoch = \", t)\n",
        "    train_loss = 0.0\n",
        "    final_model.train()\n",
        "\n",
        "    for i in range(len(X_train)):\n",
        "      try:\n",
        "        optimizer.zero_grad()\n",
        "        sentences_em = torch.FloatTensor(X_train[i].sent_embeds)\n",
        "        output = gaemodel.encode(sentences_em, X_train[i].pos_edge_index)\n",
        "        recon_loss = gaemodel.recon_loss(output, X_train[i].pos_edge_index)\n",
        "        y_pred = final_model( X_train[i], output )\n",
        "        trail_doc_embeds = np.zeros( (len(all_documents),gcn_out_dim ) )\n",
        "        loss = my_loss_function( y_pred, y_train[i] , X_train[i], output)  \n",
        "        Joint_loss = loss+recon_loss\n",
        "        Joint_loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss = train_loss + ( (1 / (i + 1)) * (Joint_loss.data - train_loss))\n",
        "      except:\n",
        "        print(\"error here = \",i)\n",
        "\n",
        "    final_model.eval()\n",
        "\n",
        "    checkpoint = {\n",
        "            'epoch': t + 1,\n",
        "            'valid_loss_min': train_loss,\n",
        "            'state_dict1': final_model.state_dict(),\n",
        "            'state_dict2':gaemodel.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),}\n",
        "\n",
        "    save_ckp(checkpoint, False, 'joint_checkpoint2.pt', 'joint_best_model2.pt')\n",
        "    print(\"loss = \", train_loss)\n",
        "    if train_loss <= train_loss_min:\n",
        "      print(' loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(train_loss_min,train_loss))\n",
        "      save_ckp(checkpoint, True,  'joint_checkpoint2.pt',  'joint_best_model2.pt')\n",
        "      train_loss_min = train_loss"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}
